{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48364429",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import pool\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, date\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "import sklearn.gaussian_process.kernels as kernels\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "from calendar import monthrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "2b214914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(pollutant, data_path=\"data/\", time_step=None, time_range=None, season=None, day_of_week=None, time_of_day=None):\n",
    "    \"\"\"\n",
    "    :param pollutant: {\"CO\", \"NO2\", \"O3\", \"SO2\", \"PM10\", \"PM25\"}\n",
    "    :param data_path: path to data directory\n",
    "    :param time_step: if provided, {\"H\", \"D\", \"M\", \"Y\"}\n",
    "    :param time_range: if provided, get data within the given time_range, inclusive\n",
    "            If second element isn't provided, defaults to present day\n",
    "    :param season: if provided, {\"winter\", \"spring\", \"summer\", \"autumn\"} for seasonal buckets\n",
    "            Winter: December, January, Ferbruary\n",
    "            Spring: March, April and May\n",
    "            Summer: June, July and August\n",
    "            Autumn: September, October and November\n",
    "    :param dayOfWeek: if provided, {\"weekday\", \"weekend\"}\n",
    "    :param timeOfDay: if provided, {\"day\", \"night\"}\n",
    "    \"\"\"\n",
    "    # temporary code for multi pollutant testing; need dictionary to track this\n",
    "    temp_pol = pollutant\n",
    "    if pollutant == \"NO2+\":\n",
    "        pollutant = \"NO2\"\n",
    "\n",
    "    df = pd.read_csv(f\"{data_path}{pollutant}.csv\", parse_dates=[\"date\"])\n",
    "\n",
    "    # TODO: FILTER OUT NEGATIVE VALUES FROM DF\n",
    "    # get data within a given time range\n",
    "    if time_range:\n",
    "        start, end = time_range\n",
    "        if not end:\n",
    "            end = datetime.today\n",
    "        df = df.loc[(df[\"date\"] >= start) & (df[\"date\"] <= end)]\n",
    "\n",
    "    df = df.set_index(\"date\")\n",
    "    # daily, monthly, yearly\n",
    "    if time_step in {\"D\", \"M\", \"Y\"}:\n",
    "        index_format = {\"D\": \"%Y-%m-%d\", \"M\": \"%Y-%m\", \"Y\": \"%Y\"}\n",
    "        df = df.groupby(by=[\"code\"]).resample(time_step).mean().dropna().reset_index()\n",
    "        # df[\"date\"] = df[\"date\"].apply(lambda x: x.strftime(index_format[time_step]))\n",
    "\n",
    "    # seasonal buckets\n",
    "    if season:\n",
    "        months = [12, 1, 2] if season == \"winter\" \\\n",
    "            else [i for i in range(3, 6)] if season == \"spring\" \\\n",
    "                else [i for i in range(6, 9)] if season == \"summer\" \\\n",
    "                    else [i for i in range(9, 12)] if season == \"autumn\" else [i for i in range(12)]\n",
    "\n",
    "        df[\"Month\"] = pd.DatetimeIndex(df['date']).month\n",
    "        # print(df)\n",
    "\n",
    "        # define condition: month must be within seasonal month range\n",
    "        condition = ((df.Month >= months[0]) & (df.Month <= months[-1]))\n",
    "        if season == \"winter\":\n",
    "            condition = ((df.Month >= months[0]) | (df.Month <= months[-1]))\n",
    "        df = df.loc[condition]\n",
    "        \n",
    "        # print(df)\n",
    "        # print(\"Season: \", season, \" , \", months)\n",
    "        # print(\"Season Months: \", df.Month.unique())\n",
    "\n",
    "        # drop created month column\n",
    "        df = df.drop([\"Month\"], axis=1)\n",
    "        print(df)\n",
    "        \n",
    "    # day of week buckets: weekday vs weekend\n",
    "    if dayOfWeek:\n",
    "        days = [i for i in range(5)] if dayOfWeek == \"weekday\" else [i for i in range(5,7)]\n",
    "\n",
    "        df[\"DayOfWeek\"] = pd.DatetimeIndex(df['date']).dayofweek\n",
    "\n",
    "        condition = ((df.DayOfWeek >= days[0]) & (df.DayOfWeek <= days[-1]))\n",
    "        df = df.loc[condition]\n",
    "\n",
    "        # print(df)\n",
    "        # print(\"Day of week: \", dayOfWeek, \" , \", days)\n",
    "        # print(\"Day of week days: \", df.DayOfWeek.unique())\n",
    "\n",
    "        df = df.drop([\"DayOfWeek\"], axis=1)\n",
    "    \n",
    "    # daytime (7am - 5pm) vs nighttime (5pm - 7am) buckets, according to London's sunrise and sunset times\n",
    "    if timeOfDay:\n",
    "        hours = [i for i in range(7, 18)] if timeOfDay == \"day\" else [i%24 for i in range(18, 31)]\n",
    "\n",
    "        df[\"Hour\"] = pd.DatetimeIndex(df['date']).hour\n",
    "\n",
    "        condition = ((df.Hour >= hours[0]) & (df.Hour <= hours[-1]))\n",
    "        if timeOfDay == \"night\":\n",
    "            condition = ((df.Hour >= hours[0]) | (df.Hour <= hours[-1]))\n",
    "        df = df.loc[condition]\n",
    "\n",
    "        # print(df)\n",
    "        # print(\"Time of day: \", timeOfDay, \" , \", hours)\n",
    "        # print(\"Hours of time of day in df: \", df.Hour.unique())\n",
    "\n",
    "        df = df.drop([\"Hour\"], axis=1)\n",
    "\n",
    "    # filter negative values; data cleaning\n",
    "    if temp_pol == \"NO2\":\n",
    "        df = df[(df[\"no2\"] > 0)]\n",
    "    elif temp_pol == \"NO2+\":\n",
    "        df = df[(df[\"no2\"] > 0) & (df[\"nox\"] > 0)]\n",
    "        \n",
    "    # generate time_step (t) column\n",
    "    df = df.sort_values(\"date\")\n",
    "    dates = df[\"date\"].values\n",
    "\n",
    "    t = -1\n",
    "    current_date = None\n",
    "    time_steps = []\n",
    "    for date in dates:\n",
    "        if date != current_date:\n",
    "            t += 1\n",
    "            current_date = date\n",
    "        time_steps.append(t)\n",
    "    df[\"t\"] = time_steps\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e4a04af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, test_percent=0.2):\n",
    "    \"\"\"\n",
    "    returns: train_df, test_df, train_indices, test_indices\n",
    "    \"\"\"\n",
    "    N, M = df.shape\n",
    "    indices = np.arange(N)\n",
    "    train_indices, test_indices = train_test_split(indices, test_size=test_percent)\n",
    "    train_df, test_df = df.iloc[train_indices, :], df.iloc[test_indices, :]\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a65b6626",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(train_df, test_df, features):\n",
    "    scalers = {}\n",
    "    for feature in features:\n",
    "        scaler = StandardScaler()\n",
    "        train_df[f\"scaled_{feature}\"] = scaler.fit_transform(train_df[[feature]].values)\n",
    "        test_df[f\"scaled_{feature}\"] = scaler.transform(test_df[[feature]].values)\n",
    "        scalers[feature] = scaler\n",
    "    return scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "741eecc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_GPR_model(kernel, train_df, x_features, y_features):\n",
    "    model = GaussianProcessRegressor(kernel=kernel, alpha=1e-10, n_restarts_optimizer=0, normalize_y=True)\n",
    "    model.fit(train_df[x_features], train_df[y_features])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "185deb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(filename, df, model, train_df, test_df, train_scalers):\n",
    "    path = f\"GPR-models/{filename}/\"\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    \n",
    "    df_filename = f\"{path}{filename}_df.sav\"\n",
    "    model_filename = f\"{path}{filename}_model.sav\"\n",
    "    train_df_filename = f\"{path}{filename}_train_df.sav\"\n",
    "    test_df_filename = f\"{path}{filename}_test_df.sav\"\n",
    "    scalers_filename = f\"{path}{filename}_scalers.sav\"\n",
    "    pickle.dump(df, open(df_filename, \"wb\"))\n",
    "    pickle.dump(model, open(model_filename, \"wb\"))\n",
    "    pickle.dump(test_df, open(train_df_filename, \"wb\"))\n",
    "    pickle.dump(train_df, open(test_df_filename, \"wb\"))\n",
    "    pickle.dump(train_scalers, open(scalers_filename, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "953706d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model(model, train_df, test_df, x_fixed_features, x_features, y_features, codes, title=\"Predictions after training\", save_path=\"GPR_figures/\"):\n",
    "    min_t, max_t = df[\"t\"].min(), df[\"t\"].max()\n",
    "    time_steps = np.linspace(min_t, max_t, max_t-min_t+1)\n",
    "    start_date, end_date = df[\"date\"].min(), df[\"date\"].max()\n",
    "    delta = end_date - start_date\n",
    "    dates = [start_date + timedelta(days=i) for i in range(delta.days+1)]\n",
    "    \n",
    "    for code in codes:\n",
    "        plt.figure()\n",
    "        plt.subplots(facecolor=\"white\")\n",
    "        \n",
    "        site_train_df, site_test_df = train_df.loc[train_df[\"code\"] == code], test_df.loc[test_df[\"code\"] == code]\n",
    "        \n",
    "        # PREDICT POLLUTION AT SITE ACROSS ALL DATES IN TIME RANGE\n",
    "        site_prediction_df = pd.DataFrame({\"t\": time_steps})\n",
    "        for fixed_feature in x_fixed_features:\n",
    "            site_prediction_df[fixed_feature] = site_train_df.iloc[0][fixed_feature]\n",
    "        site_prediction_df = site_prediction_df[x_features]\n",
    "        \n",
    "        # PLOT PREDICTION\n",
    "        prediction_mean, prediction_std = model.predict(site_prediction_df, return_std=True)\n",
    "        prediction_mean, prediction_std = prediction_mean.flatten(), prediction_std.flatten()\n",
    "        (line,) = plt.plot(dates, prediction_mean, lw=1.5, label=\"Mean of predictive posterior\")\n",
    "        plt.fill_between(\n",
    "            dates,\n",
    "            prediction_mean-1.96*prediction_std,\n",
    "            prediction_mean+1.96*prediction_std,\n",
    "            color=line.get_color(),\n",
    "            alpha=0.6,\n",
    "            label=r\"95% confidence interval\"\n",
    "        )\n",
    "        \n",
    "        # PLOT OBSERVED (TRAIN) DATA\n",
    "        plt.plot(site_train_df[\"date\"], site_train_df[y_features], \"x\", label=\"Training observations\", alpha=0.9, color=\"grey\", linestyle=\"None\")\n",
    "        \n",
    "        # PREDICT TEST DATA\n",
    "        test_mean, test_std = model.predict(site_test_df[x_features], return_std=True)\n",
    "        test_mean, test_std = test_mean.flatten(), test_std.flatten()\n",
    "\n",
    "        # PLOT TEST ACTUAL VALUE\n",
    "        plt.plot(site_test_df[\"date\"], site_test_df[y_features], \".\", label=\"Testing actual value\", alpha=0.75, color=\"red\", linestyle=\"None\")\n",
    "        \n",
    "        # PLOT DIFFERENCE BETWEEN TEST PREDICTION AND ACTUAL VALUE\n",
    "        test_dates = site_test_df[\"date\"].values\n",
    "        plt.plot((test_dates, test_dates), (test_mean, site_test_df[y_features].values.flatten()), c='red')# , label=\"Prediction error\")\n",
    "        \n",
    "        # PLOT TEST PREDICTION\n",
    "        plt.plot(site_test_df[\"date\"], test_mean, \"o\", label=\"Testing predictions\", alpha=0.75, color=\"blue\", linestyle=\"None\")\n",
    "        # percent_error = np.absolute(1 - np.divide(test_mean, site_test_df[y_features].values.flatten()))*100\n",
    "        # plt.scatter(site_test_df[\"date\"], test_mean, c=percent_error, vmin=0, vmax=round(np.max(percent_error)), cmap=\"bwr\", label=\"Testing points\")\n",
    "        # plt.colorbar()\n",
    "        \n",
    "        # SCORE TEST DATA\n",
    "        score = model.score(site_test_df[x_features], site_test_df[y_features])\n",
    "        \n",
    "        plt.title(f\"Model predictions for site {code}\\n R^2 (n={site_test_df.shape[0]}): {score}\")\n",
    "        plt.xlabel(f\"Date\")\n",
    "        plt.ylabel(f\"Concentration of NO2 (ug/m3)\")\n",
    "\n",
    "        # create folder for model run\n",
    "        isExist = os.path.exists(save_path)\n",
    "        if not isExist:\n",
    "            os.makedirs(save_path)\n",
    "\n",
    "        plt.gcf().autofmt_xdate()\n",
    "        \n",
    "        handles, labels = plt.gca().get_legend_handles_labels()\n",
    "        by_label = dict(zip(labels, handles))\n",
    "        plt.legend(by_label.values(), by_label.keys())\n",
    "        plt.legend(loc=(1.04,0))\n",
    "        \n",
    "        plt.savefig(fname=save_path + \"prediction_\" + code + \".png\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "0e6313ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SPECIFY DATA PARAMETERS\n",
    "\"\"\"\n",
    "pollutant = \"NO2+\"\n",
    "time_step = \"D\"\n",
    "time_range = (datetime(2020, 12, 1), datetime(2020, 12, 31))\n",
    "season = None\n",
    "day_of_week = None\n",
    "time_of_day = None\n",
    "field_strings = filter(None, [pollutant, timestep, time_range[0].strftime(\"%m%d%Y\"), time_range[1].strftime(\"%m%d%Y\"), season, dayOfWeek, timeOfDay])\n",
    "\n",
    "random_id = random.randint(0, 10000)\n",
    "figure_title = \"_\".join(field_strings)\n",
    "filename = figure_title = f\"{random_id}_{figure_title}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "f76c213d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3194_NO2+_D_12012020_12312020'"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "b0f05682",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data(pollutant, data_path=\"../../data/\", time_step=time_step, time_range=time_range, season=season, day_of_week=day_of_week, time_of_day=time_of_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "977e0d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>date</th>\n",
       "      <th>nox</th>\n",
       "      <th>no2</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BG1</td>\n",
       "      <td>2020-12-01</td>\n",
       "      <td>26.770684</td>\n",
       "      <td>20.132520</td>\n",
       "      <td>51.563752</td>\n",
       "      <td>0.177891</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>BY7</td>\n",
       "      <td>2020-12-01</td>\n",
       "      <td>61.988146</td>\n",
       "      <td>38.335063</td>\n",
       "      <td>51.405546</td>\n",
       "      <td>0.018882</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1821</th>\n",
       "      <td>NM2</td>\n",
       "      <td>2020-12-01</td>\n",
       "      <td>44.963835</td>\n",
       "      <td>32.840343</td>\n",
       "      <td>51.537598</td>\n",
       "      <td>-0.002138</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>CD1</td>\n",
       "      <td>2020-12-01</td>\n",
       "      <td>138.486986</td>\n",
       "      <td>56.154598</td>\n",
       "      <td>51.544219</td>\n",
       "      <td>-0.175284</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790</th>\n",
       "      <td>NB1</td>\n",
       "      <td>2020-12-01</td>\n",
       "      <td>57.462037</td>\n",
       "      <td>41.753488</td>\n",
       "      <td>51.511970</td>\n",
       "      <td>-0.116713</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     code       date         nox        no2   latitude  longitude  t\n",
       "0     BG1 2020-12-01   26.770684  20.132520  51.563752   0.177891  0\n",
       "310   BY7 2020-12-01   61.988146  38.335063  51.405546   0.018882  0\n",
       "1821  NM2 2020-12-01   44.963835  32.840343  51.537598  -0.002138  0\n",
       "339   CD1 2020-12-01  138.486986  56.154598  51.544219  -0.175284  0\n",
       "1790  NB1 2020-12-01   57.462037  41.753488  51.511970  -0.116713  0"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "d6e6c37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = split_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "0f060229",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexherrera/opt/anaconda3/envs/london-aq/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/Users/alexherrera/opt/anaconda3/envs/london-aq/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/alexherrera/opt/anaconda3/envs/london-aq/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/Users/alexherrera/opt/anaconda3/envs/london-aq/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "scaled_features = [\"latitude\", \"longitude\"]\n",
    "train_scalers = scale_data(train_df, test_df, [\"latitude\", \"longitude\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "b318fe98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SPECIFY KERNEL PARAMETERS\n",
    "\"\"\"\n",
    "PERIODICITY = 7\n",
    "kernel = kernels.ExpSineSquared(periodicity=PERIODICITY)*kernels.RBF([0, 0, 1.0]) + kernels.RBF([1.0, 1.0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "fa7ea276",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexherrera/opt/anaconda3/envs/london-aq/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:285: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/alexherrera/opt/anaconda3/envs/london-aq/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:427: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  ConvergenceWarning,\n",
      "/Users/alexherrera/opt/anaconda3/envs/london-aq/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:427: ConvergenceWarning: The optimal value found for dimension 1 of parameter k1__k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  ConvergenceWarning,\n",
      "/Users/alexherrera/opt/anaconda3/envs/london-aq/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:427: ConvergenceWarning: The optimal value found for dimension 2 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  ConvergenceWarning,\n"
     ]
    }
   ],
   "source": [
    "train_x_features = [\"scaled_latitude\", \"scaled_longitude\", \"t\"]\n",
    "train_y_features = [\"no2\", \"nox\"]\n",
    "model = train_GPR_model(kernel, train_df, train_x_features, train_y_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "c4fae975",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(filename, df, model, train_df, test_df, train_scalers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "df45b274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['scaled_latitude', 'scaled_longitude', 't'], dtype=object)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.feature_names_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "38400996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7218586547398784"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(test_df[train_x_features], test_df[train_y_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "ac08e071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>date</th>\n",
       "      <th>nox</th>\n",
       "      <th>no2</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>t</th>\n",
       "      <th>scaled_latitude</th>\n",
       "      <th>scaled_longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>HR1</td>\n",
       "      <td>2020-12-07</td>\n",
       "      <td>50.671930</td>\n",
       "      <td>40.522617</td>\n",
       "      <td>51.617327</td>\n",
       "      <td>-0.298775</td>\n",
       "      <td>6</td>\n",
       "      <td>2.020965</td>\n",
       "      <td>-1.532807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>KT4</td>\n",
       "      <td>2020-12-16</td>\n",
       "      <td>85.817711</td>\n",
       "      <td>41.278972</td>\n",
       "      <td>51.379312</td>\n",
       "      <td>-0.281259</td>\n",
       "      <td>15</td>\n",
       "      <td>-2.067800</td>\n",
       "      <td>-1.402326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>LH0</td>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>24.212889</td>\n",
       "      <td>19.006051</td>\n",
       "      <td>51.488780</td>\n",
       "      <td>-0.441627</td>\n",
       "      <td>28</td>\n",
       "      <td>-0.187293</td>\n",
       "      <td>-2.596950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2486</th>\n",
       "      <td>WAB</td>\n",
       "      <td>2020-12-15</td>\n",
       "      <td>102.911954</td>\n",
       "      <td>45.485337</td>\n",
       "      <td>51.429331</td>\n",
       "      <td>-0.166524</td>\n",
       "      <td>14</td>\n",
       "      <td>-1.208544</td>\n",
       "      <td>-0.547634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503</th>\n",
       "      <td>WAC</td>\n",
       "      <td>2020-12-01</td>\n",
       "      <td>70.680828</td>\n",
       "      <td>44.407037</td>\n",
       "      <td>51.463690</td>\n",
       "      <td>-0.166713</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.618298</td>\n",
       "      <td>-0.549046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     code       date         nox        no2   latitude  longitude   t  \\\n",
       "1211  HR1 2020-12-07   50.671930  40.522617  51.617327  -0.298775   6   \n",
       "1437  KT4 2020-12-16   85.817711  41.278972  51.379312  -0.281259  15   \n",
       "1636  LH0 2020-12-29   24.212889  19.006051  51.488780  -0.441627  28   \n",
       "2486  WAB 2020-12-15  102.911954  45.485337  51.429331  -0.166524  14   \n",
       "2503  WAC 2020-12-01   70.680828  44.407037  51.463690  -0.166713   0   \n",
       "\n",
       "      scaled_latitude  scaled_longitude  \n",
       "1211         2.020965         -1.532807  \n",
       "1437        -2.067800         -1.402326  \n",
       "1636        -0.187293         -2.596950  \n",
       "2486        -1.208544         -0.547634  \n",
       "2503        -0.618298         -0.549046  "
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "55a36e94",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (31,) and (62,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6c/3n2fd4rj4l3gj84562cjz0kr0000gn/T/ipykernel_21615/3336408959.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msite_codes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"code\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"GPR_figures/{filename}/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_fixed_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msite_codes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/6c/3n2fd4rj4l3gj84562cjz0kr0000gn/T/ipykernel_21615/2047841407.py\u001b[0m in \u001b[0;36mplot_model\u001b[0;34m(model, train_df, test_df, x_fixed_features, x_features, y_features, codes, title, save_path)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mprediction_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msite_prediction_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_std\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mprediction_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction_mean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_std\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Mean of predictive posterior\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         plt.fill_between(\n\u001b[1;32m     25\u001b[0m             \u001b[0mdates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/london-aq/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3019\u001b[0m     return gca().plot(\n\u001b[1;32m   3020\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3021\u001b[0;31m         **({\"data\": data} if data is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   3022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/london-aq/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \"\"\"\n\u001b[1;32m   1604\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/london-aq/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/london-aq/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    502\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (31,) and (62,)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_fixed_features = [\"scaled_latitude\", \"scaled_longitude\"]\n",
    "site_codes = df[\"code\"].unique()\n",
    "save_path = f\"GPR_figures/{filename}/\"\n",
    "plot_model(model, train_df, test_df, x_fixed_features, train_x_features, train_y_features, site_codes, save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767f117c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "LOAD MODEL\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99c5776",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TRANSFORM SAVED MODELS TO FIT THIS NEW WORKFLOW\n",
    "\"\"\"\n",
    "filename = \"2679_NO2_D_09012020_12312020\"\n",
    "df = pickle.load(open(f\"{filename}_df.sav\", \"rb\"))\n",
    "\n",
    "df = df.sort_values(\"date\")\n",
    "dates = df[\"date\"].values\n",
    "\n",
    "t = -1\n",
    "current_date = None\n",
    "time_steps = []\n",
    "for date in dates:\n",
    "    if date != current_date:\n",
    "        t += 1\n",
    "        current_date = date\n",
    "    time_steps.append(t)\n",
    "df[\"t\"] = time_steps\n",
    "\n",
    "df = df.rename(columns={'norm_lat': 'scaled_latitude', 'norm_lon': 'scaled_longitude'})\n",
    "    \n",
    "model = pickle.load(open(f\"{filename}_model.sav\", \"rb\"))\n",
    "train_indices, test_indices = pickle.load(open(f\"{filename}_indices.sav\", \"rb\"))\n",
    "train_scalers = pickle.load(open(f\"{filename}_scalers.sav\", \"rb\"))\n",
    "site_codes = df[\"code\"].unique()\n",
    "train_df, test_df = df.iloc[train_indices, :], df.iloc[test_indices, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bc9395",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
